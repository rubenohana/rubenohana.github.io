<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Ruben Ohana</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Ruben Ohana</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Ruben Ohana</h1>
</div>
<table class="imgtable"><tr><td>
<img src="photo.jpg" alt="" width="170px" height="250px" />&nbsp;</td>
<td align="left"><h2>Briefly</h2>

<p> I am a first-year Ph.D. student under the supervision of <a href="https://florentkrzakala.com/"> Florent Krzakala</a> (LPENS),<a href="https://www.di.ens.fr/~rudi/">Alessandro Rudi</a> (INRIA - DIENS, Sierra Team) and  <a href="https://scholar.google.fr/citations?user=PCIAcfUAAAAJ&hl=en">Laurent Daudet</a>. I do research in Machine Learning at the Ecole Normale Supérieure in Paris and in collaboration with the startup <a href="https://lighton.ai/" > LightON </a>.
<p> My research interest focus on kernels methods, statistics, random matrices and deep learning. More precisely, my current work focuses on using Random Features to approximate kernel methods and to study deep learning frameworks such as Reservoir Computing. 
Before my starting my Ph.D., I graduated with an engineering degree in Physics from <a href="https://www.espci.psl.eu/en/"> ESPCI Paris </a>, an MSc in Condensed Matter from the  <a href="https://www.phys.ens.fr/spip.php?rubrique284&lang=en"> Master ICFP</a> at the <a href="https://www.ens.psl.eu "> Ecole Normale Supérieure</a> and an MSc in Statistics/Machine Learning from the Master in Mathematics at <a href="https://www.sorbonne-universite.fr/en/university"> Sorbonne University</a>.
I did an internship at <a href="http://www.brl.ntt.co.jp/E/">NTT Basic Research Laboratory</a> in Japan, where I worked on the Quantum spin Hall Effect in InAS/GaSb double quantum wells, experimentally and theoretically under the supervision of <a href="http://www.brl.ntt.co.jp/people/irie.hiroshi/">Irie Hiroshi</a>. I also did my first master thesis at the <a href="https://www.ligo.caltech.edu/"> LIGO</a> (the gravitational wave observatory), at the <a href="https://www.mit.edu/">Massachussetts Institute of Technology</a>, where I studied the next generation of lasers that will be integrated in the next update of the interferometer. I did my second master thesis at the <a href="http://www.quantuminfolip6.fr/">Quantum Information Group</a> at the <a href="https://www.lip6.fr/?LANG=en LIP6"> LIP6</a> at Sorbonne University.  	

<a href=""></a>

<p>Here is a short <a href="cv_english.pdf">CV</a>.</p>
<h2>Contact</h2>
<ul>
<li><p>E-mail: ruben [dot] ohana [at] phys [dot] ens [dot] fr <br />
</li>
<li><p>Physical address: LPENS, Ecole Normale Supérieure <a href="https://www.google.com/maps/place/24+Rue+Lhomond,+75005+Paris/data=!4m2!3m1!1s0x47e671e905a58849:0x6c1d0dc24c54a979?sa=X&ved=2ahUKEwiVqMvA86HrAhULzoUKHZCRAA0Q8gEwAHoECAsQAQ">   24 rue Lhomond, 75005 Paris </a>. </p> 
</li>
</ul>
</td></tr></table>
<h2>Publications and Preprints</h2>
<ul>
<li><p>J. Dong<sup>*</sup>, <b>R. Ohana<sup>*</sup></b>, M. Rafayelyan, F. Krzakala.  <b>Reservoir Computing meets Recurrent Kernels and Structured Transforms*, </b> 2020, preprint. <br />[<a href="https://arxiv.org/abs/2006.07310">arXiv</a>] <span class="toggle-trigger">[Show Abstract]<span> 
<div class="toggle-wrap">
<b>Abstract:</b> Reservoir Computing is a class of simple yet efficient Recurrent Neural Networks where internal weights are fixed at random and only a linear output layer is trained. In the large size limit, such random neural networks have a deep connection with kernel methods. Our contributions are threefold: a) We rigorously establish the recurrent kernel limit of Reservoir Computing and prove its convergence. b) We test our models on chaotic time series prediction, a classic but challenging benchmark in Reservoir Computing, and show how the Recurrent Kernel is competitive and computationally efficient when the number of data points remains moderate. c) When the number of samples is too large, we leverage the success of structured Random Features for kernel approximation by introducing Structured Reservoir Computing. The two proposed methods, Recurrent Kernel and Structured Reservoir Computing, turn out to be much faster and more memory-efficient than conventional Reservoir Computing. 
</div></p>
</li>
</ul>
<ul>
<li><p><b>R. Ohana</b>, J. Wacker, J. Dong, S. Marmin, F. Krzakala, M. Filippone, L. Daudet. <b>Kernel Computations from large-scale random features obtained by Optical Processing Units</b>, 2020, <i> International Conference on Acoustics, Speech, and Signal Processing (ICASSP) </i>. <br />[<a href="https://ieeexplore.ieee.org/abstract/document/9053272">Conference paper</a>,  <a href="https://arxiv.org/abs/1910.09880">arXiv</a>] <span class="toggle-trigger">[Show Abstract]<span> 
<div class="toggle-wrap">
<b>Abstract:</b> Approximating kernel functions with random features (RFs) has been a successful application of random projections for nonparametric estimation. However, performing random projections presents computational challenges for large-scale problems. Recently, a new optical hardware called Optical Processing Unit (OPU) has been developed for fast and energy-efficient computation of large-scale RFs in the analog domain. More specifically, the OPU performs the multiplication of input vectors by a large random matrix with complex-valued i.i.d. Gaussian entries, followed by the application of an element-wise squared absolute value operation - this last nonlinearity being intrinsic to the sensing process. In this paper, we show that this operation results in a dot-product kernel that has connections to the polynomial kernel, and we extend this computation to arbitrary powers of the feature map. Experiments demonstrate that the OPU kernel and its RF approximation achieve competitive performance in applications using kernel ridge regression and transfer learning for image classification. Crucially, thanks to the use of the OPU, these results are obtained with time and energy savings. 
</div></p>
</li>
</ul>
<ul>
<li><p>H. Irie, T. Akiho, F. Couedo, R. Ohana, S. Suzuki, H. Onomitsu, K. Muraki. <b>Impact of epitaxial strain on the topological-nontopological phase diagram and semimetallic behavior of InAs/GaSb composite quantum wells</b>, 2020, <i>Physical Review B </i> <br />[<a href="https://journals.aps.org/prb/abstract/10.1103/PhysRevB.101.075433">Phys. Rev. B</a>, <a href="https://arxiv.org/abs/2002.12503v1">arXiv</a>] <span class="toggle-trigger">[Show Abstract]<span> 
<div class="toggle-wrap">
<b>Abstract:</b> We study the influence of epitaxial strain on the electronic properties of InAs/GaSb composite quantum wells (CQWs), host structures for quantum spin Hall insulators, by transport measurements and eight-band <i>k⋅p</i> calculations. Using different substrates and buffer layer structures for crystal growth, we prepare two types of samples with vastly different strain conditions. CQWs with a nearly strain-free GaSb layer exhibit a resistance peak at the charge neutrality point that reflects the opening of a topological gap in the band-inverted regime. In contrast, for CQWs with 0.50% biaxial tensile strain in the GaSb layer, semimetallic behavior indicating a gap closure is found for the same degree of band inversion. Additionally, with the tensile strain, the boundary between the topological and nontopological regimes is located at a larger InAs thickness. Eight-band <i>k⋅p</i>  calculations reveal that tensile strain in GaSb not only shifts the phase boundary but also significantly modifies the band structure, which can result in the closure of an indirect gap and make the system semimetallic even in the topological regime. Our results thus provide a global picture of the topological-nontopological phase diagram as a function of layer thicknesses and strain. 
</div></p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2020-06-16 11:22:34 CEST, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
</div>
</div>
</td>
</tr>
</table>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<script>
$(document).ready(function() {
    $(".toggle-trigger").click(function() {
        $(this).parent().nextAll('.toggle-wrap').first().slideToggle('slow');
    });
});
</script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-128753599-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
